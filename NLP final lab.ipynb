{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6901cb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\pc\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\pc\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\pc\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pc\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk \n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "893c2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Natural language processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans through natural language. The ultimate goal of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both meaningful and useful. Applications of NLP are vast and include machine translation, sentiment analysis, speech recognition, and chatbots. As technology advances, the ability of machines to understand and interact with human language is becoming increasingly sophisticated, making NLP an exciting and rapidly evolving field.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31f0d56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first letter upper case:  Natural Language Processing (Nlp) Is A Subfield Of Artificial Intelligence (Ai) That Focuses On The Interaction Between Computers And Humans Through Natural Language. The Ultimate Goal Of Nlp Is To Enable Computers To Understand, Interpret, And Generate Human Languages In A Way That Is Both Meaningful And Useful. Applications Of Nlp Are Vast And Include Machine Translation, Sentiment Analysis, Speech Recognition, And Chatbots. As Technology Advances, The Ability Of Machines To Understand And Interact With Human Language Is Becoming Increasingly Sophisticated, Making Nlp An Exciting And Rapidly Evolving Field.\n",
      "###\n",
      "punctation removal:  Natural Language Processing Nlp Is A Subfield Of Artificial Intelligence Ai That Focuses On The Interaction Between Computers And Humans Through Natural Language The Ultimate Goal Of Nlp Is To Enable Computers To Understand Interpret And Generate Human Languages In A Way That Is Both Meaningful And Useful Applications Of Nlp Are Vast And Include Machine Translation Sentiment Analysis Speech Recognition And Chatbots As Technology Advances The Ability Of Machines To Understand And Interact With Human Language Is Becoming Increasingly Sophisticated Making Nlp An Exciting And Rapidly Evolving Field\n",
      "###\n",
      "count of tokent=  Counter({'And': 7, 'Nlp': 4, 'Is': 4, 'Of': 4, 'Language': 3, 'The': 3, 'To': 3, 'Natural': 2, 'A': 2, 'That': 2, 'Computers': 2, 'Understand': 2, 'Human': 2, 'Processing': 1, 'Subfield': 1, 'Artificial': 1, 'Intelligence': 1, 'Ai': 1, 'Focuses': 1, 'On': 1, 'Interaction': 1, 'Between': 1, 'Humans': 1, 'Through': 1, 'Ultimate': 1, 'Goal': 1, 'Enable': 1, 'Interpret': 1, 'Generate': 1, 'Languages': 1, 'In': 1, 'Way': 1, 'Both': 1, 'Meaningful': 1, 'Useful': 1, 'Applications': 1, 'Are': 1, 'Vast': 1, 'Include': 1, 'Machine': 1, 'Translation': 1, 'Sentiment': 1, 'Analysis': 1, 'Speech': 1, 'Recognition': 1, 'Chatbots': 1, 'As': 1, 'Technology': 1, 'Advances': 1, 'Ability': 1, 'Machines': 1, 'Interact': 1, 'With': 1, 'Becoming': 1, 'Increasingly': 1, 'Sophisticated': 1, 'Making': 1, 'An': 1, 'Exciting': 1, 'Rapidly': 1, 'Evolving': 1, 'Field': 1})\n",
      "###\n",
      "stopwords removal:  ['Natural', 'Language', 'Processing', 'Nlp', 'Subfield', 'Artificial', 'Intelligence', 'Ai', 'Focuses', 'Interaction', 'Computers', 'Humans', 'Natural', 'Language', 'Ultimate', 'Goal', 'Nlp', 'Enable', 'Computers', 'Understand', 'Interpret', 'Generate', 'Human', 'Languages', 'Way', 'Meaningful', 'Useful', 'Applications', 'Nlp', 'Vast', 'Include', 'Machine', 'Translation', 'Sentiment', 'Analysis', 'Speech', 'Recognition', 'Chatbots', 'Technology', 'Advances', 'Ability', 'Machines', 'Understand', 'Interact', 'Human', 'Language', 'Becoming', 'Increasingly', 'Sophisticated', 'Making', 'Nlp', 'Exciting', 'Rapidly', 'Evolving', 'Field']\n"
     ]
    }
   ],
   "source": [
    "#1. make every first letter upper case\n",
    "new_text = text.title()\n",
    "print(\"first letter upper case: \" ,new_text)\n",
    "print(\"###\")\n",
    "\n",
    "#2. punctation removal\n",
    "import string\n",
    "clean_text = new_text.translate(str.maketrans('','',string.punctuation))\n",
    "print(\"punctation removal: \", clean_text)\n",
    "print(\"###\")\n",
    "\n",
    "#3.tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_text = word_tokenize(clean_text)\n",
    "\n",
    "#4.prints the count of each token\n",
    "from collections import Counter\n",
    "print(\"count of tokent= \", Counter(tokenized_text))\n",
    "print(\"###\")\n",
    "\n",
    "#5.stopwords removal\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "no_sw = [w for w in tokenized_text if w.lower() not in sw]\n",
    "print(\"stopwords removal: \" ,no_sw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b45ef85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', 'nlp', 'subfield', 'artifici', 'intellig', 'ai', 'focus', 'interact', 'comput', 'human', 'natur', 'languag', 'ultim', 'goal', 'nlp', 'enabl', 'comput', 'understand', 'interpret', 'gener', 'human', 'languag', 'way', 'meaning', 'use', 'applic', 'nlp', 'vast', 'includ', 'machin', 'translat', 'sentiment', 'analysi', 'speech', 'recognit', 'chatbot', 'technolog', 'advanc', 'abil', 'machin', 'understand', 'interact', 'human', 'languag', 'becom', 'increasingli', 'sophist', 'make', 'nlp', 'excit', 'rapidli', 'evolv', 'field']\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "stemmed= [ps.stem(w) for w in no_sw]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e896208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'Nlp', 'Subfield', 'Artificial', 'Intelligence', 'Ai', 'Focuses', 'Interaction', 'Computers', 'Humans', 'Natural', 'Language', 'Ultimate', 'Goal', 'Nlp', 'Enable', 'Computers', 'Understand', 'Interpret', 'Generate', 'Human', 'Languages', 'Way', 'Meaningful', 'Useful', 'Applications', 'Nlp', 'Vast', 'Include', 'Machine', 'Translation', 'Sentiment', 'Analysis', 'Speech', 'Recognition', 'Chatbots', 'Technology', 'Advances', 'Ability', 'Machines', 'Understand', 'Interact', 'Human', 'Language', 'Becoming', 'Increasingly', 'Sophisticated', 'Making', 'Nlp', 'Exciting', 'Rapidly', 'Evolving', 'Field']\n"
     ]
    }
   ],
   "source": [
    "#lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lm = WordNetLemmatizer()\n",
    "lemmatized = [lm.lemmatize(w) for w in no_sw]\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5460b2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_tokenized:  ['i', 'am', 'kholoud', 'terad', '.', 'i', 'love', 'fruit', 'and', 'sour', 'icecream', '.', 'i', 'hate', 'hot', 'sauce']\n",
      "pos_tags:  [('i', 'NN'), ('am', 'VBP'), ('kholoud', 'JJ'), ('terad', 'NN'), ('.', '.'), ('i', 'JJ'), ('love', 'VBP'), ('fruit', 'NN'), ('and', 'CC'), ('sour', 'JJ'), ('icecream', 'NN'), ('.', '.'), ('i', 'JJ'), ('hate', 'VBP'), ('hot', 'JJ'), ('sauce', 'NN')]\n",
      "identifies_entities:  []\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize , sent_tokenize\n",
    "\n",
    "text= \"i am kholoud terad. i love fruit and sour icecream. i hate hot sauce\"\n",
    "\n",
    "word_tokenized= word_tokenize(text)\n",
    "print(\"word_tokenized: \", word_tokenized)\n",
    "pos_tags = nltk.pos_tag(word_tokenized)\n",
    "print(\"pos_tags: \", pos_tags)\n",
    "\n",
    "entities = nltk.ne_chunk(pos_tags)\n",
    "identifies_entities= []\n",
    "\n",
    "for entity in entities:\n",
    "    if isinstance(entity , nltk.tree.Tree):\n",
    "        entity_label= entity.label()\n",
    "        entity_text= \" \".join([w for w, tag in entity.leaves()])\n",
    "        identifies_entities.append((entity_text, entity_label))\n",
    "        \n",
    "print(\"identifies_entities: \", identifies_entities)\n",
    "\n",
    "for entity_text, entity_label in identifies_entities:\n",
    "    print(f\"{entity_text}:{entity_label}\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
